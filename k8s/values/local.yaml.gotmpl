# 로컬 환경 - 여러 곳에서 참조되는 값만 관리

global:
  namespace: mit
  environment: development
  registry: mit-registry:5000

# HA 설정 (로컬은 단일 복제본)
replicas:
  backend: 1
  frontend: 1
  arqWorker: 1

# 이미지 태그 (로컬은 항상 latest)
images:
  backend:
    tag: "latest"
  frontend:
    tag: "latest"
  worker:
    tag: "latest"
  pullSecret: ""  # 로컬 레지스트리는 인증 불필요

# Ingress (Traefik)
ingress:
  className: traefik
  host: ""  # 로컬은 호스트 없이 (http://localhost로 접근)
  tls: false

# 앱 포트 - Deployment, Service에서 공유
backend:
  port: 8000

frontend:
  port: 80

# Database (로컬 하드코딩)
database:
  url: postgresql+asyncpg://mit:mitpassword@localhost:5432/mit

# Redis - ConfigMap, LiveKit차트에서 공유
redis:
  host: redis-master
  port: 6379

# Neo4j (로컬 하드코딩)
neo4j:
  uri: bolt://localhost:7687
  user: neo4j
  password: mitpassword

# LiveKit - Secret, LiveKit차트, ConfigMap에서 공유
# 서비스 이름 lk-server: LIVEKIT_PORT 환경변수 충돌 방지
# 포트 80: Helm 차트가 서비스 80 → 컨테이너 7880 매핑
livekit:
  host: lk-server
  port: 80
  apiKey: {{ env "LIVEKIT_API_KEY" | default "mit-api-key" }}
  apiSecret: {{ env "LIVEKIT_API_SECRET" | default "secret-change-in-production-min-32-chars" }}
  externalUrl: {{ env "LIVEKIT_EXTERNAL_URL" | default "ws://localhost/livekit" | quote }}  # Ingress 경유
  # 로컬 개발: 두 URL 모두 등록 (로컬 백엔드 + k8s 백엔드)
  webhookUrls:
    - "http://host.docker.internal:8000/api/v1/livekit/webhook"  # 로컬 백엔드
    - "http://backend:8000/api/v1/livekit/webhook"               # k8s 백엔드
  # RTC 설정 (로컬: nodeIp 비워서 자동 감지, hostNetwork 사용)
  rtc:
    nodeIp: ""
    useExternalIp: false
    tcpPort: 7881
    portRangeStart: 50000
    portRangeEnd: 50020

# JWT - Secret, ConfigMap에서 공유
jwt:
  secretKey: change-this-secret-key
  accessTokenExpireMinutes: 30
  refreshTokenExpireDays: 7

# App - ConfigMap에서 사용
app:
  debug: true
  logLevel: INFO
  corsOrigins:
    - "http://localhost"
    - "http://127.0.0.1"
  frontendBaseUrl: "http://localhost"  # 초대 링크 생성용 (로컬)

# Worker - Secret, ConfigMap에서 공유
# BACKEND_API_URL은 백엔드가 Job 생성 시 동적으로 주입 (로컬/k8s 자동 감지)
worker:
  clovaSttEndpoint: "clovaspeech-gw.ncloud.com:50051"
  # Clova STT API 키 배열 (동적 할당용)
  clovaSttSecrets:
    - {{ env "CLOVA_STT_SECRET_0" | default "" }}
    - {{ env "CLOVA_STT_SECRET_1" | default "" }}
    - {{ env "CLOVA_STT_SECRET_2" | default "" }}
    - {{ env "CLOVA_STT_SECRET_3" | default "" }}
    - {{ env "CLOVA_STT_SECRET_4" | default "" }}
  backendApiKey: {{ env "BACKEND_API_KEY" | default "" }}
  ttsServerUrl: {{ env "TTS_SERVER_URL" | default "" }}
  ttsVolumeScale: {{ env "TTS_VOLUME_SCALE" | default "0.70" }}

# NCP Clova Studio
ncp:
  clovaStudioApiKey: {{ env "NCP_CLOVASTUDIO_API_KEY" | default "" }}
  clovaRouterId: {{ env "CLOVA_ROUTER_ID" | default "" }}
  clovaRouterVersion: {{ env "CLOVA_ROUTER_VERSION" | default "1" }}

# Langfuse (LLM Observability)
langfuse:
  secretKey: {{ env "LANGFUSE_SECRET_KEY" | default "" }}
  publicKey: {{ env "LANGFUSE_PUBLIC_KEY" | default "" }}
  baseUrl: {{ env "LANGFUSE_BASE_URL" | default "https://cloud.langfuse.com" }}
  tracingEnabled: {{ env "LANGFUSE_TRACING_ENABLED" | default "true" }}

# OAuth - 외부 환경변수에서 주입
oauth:
  google:
    clientId: {{ env "GOOGLE_CLIENT_ID" | default "" }}
    clientSecret: {{ env "GOOGLE_CLIENT_SECRET" | default "" }}
    redirectUri: {{ env "GOOGLE_REDIRECT_URI" | default "" }}
  naver:
    clientId: {{ env "NAVER_CLIENT_ID" | default "" }}
    clientSecret: {{ env "NAVER_CLIENT_SECRET" | default "" }}
    redirectUri: {{ env "NAVER_REDIRECT_URI" | default "" }}

# Resources - 각 차트에서 공유
resources:
  backend:
    requests: { memory: "512Mi", cpu: "200m" }
    limits: { memory: "1Gi", cpu: "500m" }
  frontend:
    requests: { memory: "32Mi", cpu: "50m" }
    limits: { memory: "128Mi", cpu: "200m" }
  worker:
    requests: { memory: "128Mi", cpu: "100m" }
    limits: { memory: "256Mi", cpu: "500m" }
  arqWorker:
    requests: { memory: "512Mi", cpu: "200m" }
    limits: { memory: "1Gi", cpu: "500m" }
  redis:
    requests: { memory: "128Mi", cpu: "50m" }
    limits: { memory: "256Mi", cpu: "200m" }
    storage: 1Gi
  livekit:
    requests: { memory: "128Mi", cpu: "100m" }
    limits: { memory: "256Mi", cpu: "500m" }
  # Observability 스택
  prometheus:
    requests: { memory: "256Mi", cpu: "100m" }
    limits: { memory: "512Mi", cpu: "300m" }
  loki:
    requests: { memory: "128Mi", cpu: "50m" }
    limits: { memory: "256Mi", cpu: "200m" }
  alloy:
    requests: { memory: "64Mi", cpu: "50m" }
    limits: { memory: "128Mi", cpu: "100m" }
  grafana:
    requests: { memory: "64Mi", cpu: "50m" }
    limits: { memory: "128Mi", cpu: "100m" }

# Observability 설정
observability:
  prometheus:
    storage: 5Gi
  loki:
    storage: 5Gi
  grafana:
    storage: 1Gi
    adminPassword: admin

# Cloudflare Tunnel (로컬에서는 비활성화)
cloudflare:
  enabled: false
