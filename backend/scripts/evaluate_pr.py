#!/usr/bin/env python3
"""LLM-as-a-Judge í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ (generate_pr íŒŒì´í”„ë¼ì¸)

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” generate_pr íŒŒì´í”„ë¼ì¸ì˜ ì¶œë ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.
- ì…ë ¥: JSONL íŒŒì¼ (extraction_output + utterances)
- í‰ê°€ ëª¨ë¸: gpt-4o (OpenAI API)
- í‰ê°€ í•­ëª©: Factuality, Comprehensiveness, Structural Consistency, Evidence Accuracy, Clarity
- ì¶œë ¥: JSON íŒŒì¼ (í‰ê°€ ì ìˆ˜ ë° ê·¼ê±°)

ì‚¬ìš©ë²•:
    python evaluate_pr.py --input data.jsonl --output results.json
"""

import argparse
import json
import os
import sys
from pathlib import Path
from typing import Any

from dotenv import load_dotenv
from openai import OpenAI

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# =============================================================================
# ì„¤ì •
# =============================================================================

EVALUATION_CONFIG = {
    "model": "gpt-4o",
    "temperature": 0,  # ì¬í˜„ì„± í™•ë³´
    "max_tokens": 512,
    "response_format": {"type": "json_object"},
}

# Rubric ê¸°ì¤€ (rubric.md ê¸°ë°˜, LLMì´ ì´í•´í•˜ê¸° ì‰½ê²Œ ì¬êµ¬ì„±)
RUBRIC_CRITERIA = {
    "factuality": """
[Factuality (ì‚¬ì‹¤ì„±)]
ëª¨ë¸ì´ íšŒì˜ë¡ì„ ì‘ì„±í•  ë•Œ ì›ë¬¸ì— ì—†ëŠ” ë‚´ìš©ì„ ì§€ì–´ë‚´ì§€ ì•Šì•˜ëŠ”ì§€ í‰ê°€í•©ë‹ˆë‹¤.

ì ìˆ˜ ê¸°ì¤€:
- 5ì  (ì™„ë²½): ëª¨ë“  ê²°ì •ì‚¬í•­ì´ ì›ë¬¸ì— ëª…í™•í•œ ê·¼ê±°ë¥¼ ë‘ê³  ìˆìœ¼ë©°, ì‚¬ì‹¤ ì™œê³¡ì´ ì „í˜€ ì—†ìŒ
- 4ì  (ìš°ìˆ˜): ë‚´ìš©ì€ ì‚¬ì‹¤ì´ë‚˜, ë¯¸ë¯¸í•œ ë‰˜ì•™ìŠ¤ ì°¨ì´ê°€ ìˆìŒ
- 3ì  (ë³´í†µ): ì£¼ìš” ë‚´ìš©ì€ ë§ìœ¼ë‚˜, ë‚ ì§œ/ìˆ«ì/ê³ ìœ ëª…ì‚¬ ë“± ì„¸ë¶€ ì‚¬í•­ì—ì„œ ì˜¤ë¥˜ê°€ 1~2ê±´ ì¡´ì¬
- 2ì  (ë¯¸í¡): ì›ë¬¸ ë‚´ìš©ì„ ê³¼ë„í•˜ê²Œ í•´ì„í•˜ì—¬ í™”ìì˜ ì˜ë„ì™€ ë‹¤ë¥¸ ê²°ë¡  ë„ì¶œ
- 1ì  (ì‹¤íŒ¨): ì›ë¬¸ì— ì „í˜€ ì—†ëŠ” ë‚´ìš©ì„ ì°½ì¡° (ì‹¬ê°í•œ í• ë£¨ì‹œë„¤ì´ì…˜)

í‰ê°€ ì‹œ ì£¼ì˜ì‚¬í•­:
- ì›ë¬¸ ë°œí™”ì™€ ì¶”ì¶œëœ Decision/Agendaë¥¼ ì •ë°€í•˜ê²Œ ëŒ€ì¡°
- ì¶”ì •ì´ë‚˜ ì™¸ë¶€ ì§€ì‹ìœ¼ë¡œ íŒë‹¨í•˜ì§€ ë§ê³ , ì‹¤ì œ ë°œí™”ì— ê·¼ê±°ê°€ ìˆëŠ”ì§€ë§Œ í™•ì¸
""",
    "comprehensiveness": """
[Comprehensiveness (ì™„ì „ì„±)]
ì¤‘ìš”í•œ ì•ˆê±´ì´ë‚˜ ê²°ì •ì‚¬í•­ì„ ë¹ ëœ¨ë¦¬ì§€ ì•Šì•˜ëŠ”ì§€ í‰ê°€í•©ë‹ˆë‹¤.

ì ìˆ˜ ê¸°ì¤€:
- 5ì  (ì™„ë²½): íšŒì˜ì—ì„œ ë‚´ë¦° ëª¨ë“  ì£¼ìš” ê²°ì • ì‚¬í•­ì´ ë¹ ì§ì—†ì´ ì¶”ì¶œë¨
- 4ì  (ìš°ìˆ˜): ì£¼ìš” ê²°ì •ì˜ 80% ì´ìƒ í¬í•¨
- 3ì  (ë³´í†µ): ì£¼ìš” ê²°ì •ì˜ 50~80% í¬í•¨
- 2ì  (ë¯¸í¡): ì£¼ìš” ê²°ì •ì˜ 50% ë¯¸ë§Œë§Œ í¬í•¨
- 1ì  (ì‹¤íŒ¨): í•µì‹¬ ê²°ì •ì´ ê±°ì˜ ëˆ„ë½ë¨

í‰ê°€ ì‹œ ì£¼ì˜ì‚¬í•­:
- ì›ë¬¸ ì „ì²´ë¥¼ ì½ê³  ì£¼ìš” ê²°ì •ì‚¬í•­ íŒŒì•…
- ì¶”ì¶œëœ Agenda/Decisionê³¼ ë¹„êµí•˜ì—¬ ëˆ„ë½ëœ ì¤‘ìš” ì‚¬í•­ í™•ì¸
""",

    "structural_consistency": """
[Structural Consistency (êµ¬ì¡°ì  ì¼ê´€ì„±)]
Agendaì™€ Decision êµ¬ì¡°ê°€ ë…¼ë¦¬ì ìœ¼ë¡œ ì—°ê²°ë˜ì—ˆëŠ”ì§€ í‰ê°€í•©ë‹ˆë‹¤.

ì ìˆ˜ ê¸°ì¤€:
- 5ì  (ì™„ë²½): Decisionì´ ìƒìœ„ Agendaì— ë…¼ë¦¬ì ìœ¼ë¡œ ì™„ë²½íˆ ë¶€í•©í•˜ë©°, í•˜ë‚˜ì˜ Decisionì´ ë…ë¦½ì ì¸ ë‹¨ì¼ ì˜ì‚¬ê²°ì • ë‹¨ìœ„ë¡œ ê¹”ë”í•˜ê²Œ ë¶„ë¦¬ë¨
- 4ì  (ìš°ìˆ˜): Agendaì™€ì˜ ì—°ê´€ì„±ì€ ëª…í™•í•˜ë‚˜, Decisionì˜ ë‹¨ìœ„ê°€ ë‹¤ì†Œ ì•„ì‰¬ì›€ (ì˜ˆ: ë‘ ê°œì˜ ê´€ë ¨ ê²°ì •ì´ í•˜ë‚˜ë¡œ ë¬¶ì„)
- 3ì  (ë³´í†µ): Decisionì´ Agendaì™€ ê´€ë ¨ì€ ìˆìœ¼ë‚˜ ë¶„ë¥˜ê°€ ë‹¤ì†Œ ëª¨í˜¸í•˜ê±°ë‚˜, ì„œë¡œ ë‹¤ë¥¸ ì„±ê²©ì˜ ê²°ì •ì‚¬í•­ë“¤ì´ í•˜ë‚˜ë¡œ ë­‰ëš±ê·¸ë ¤ì ¸ ìˆìŒ
- 2ì  (ë¯¸í¡): Agendaì™€ì˜ ì—°ê´€ì„±ì´ ë‚®ì•„ ë§¥ë½ íŒŒì•…ì´ ì–´ë µê±°ë‚˜, ë‚´ìš©ì´ ë„ˆë¬´ í¬ê´„ì ì´ì–´ì„œ êµ¬ì²´ì ì¸ ì‹¤í–‰ ë‹¨ìœ„ ì‹ë³„ ì–´ë ¤ì›€
- 1ì  (ì‹¤íŒ¨): Decisionì´ í•´ë‹¹ Agendaì™€ ì „í˜€ ìƒê´€ì—†ê±°ë‚˜, ì˜ë¯¸ ìˆëŠ” ë‹¨ìœ„ë¡œ êµ¬ë¶„ë˜ì§€ ì•ŠìŒ

í‰ê°€ ì‹œ ì£¼ì˜ì‚¬í•­:
- Agendaì˜ topicê³¼ Decisionì˜ contentê°€ ë…¼ë¦¬ì ìœ¼ë¡œ ì—°ê²°ë˜ëŠ”ì§€ í™•ì¸
- Decisionì´ ì§€ë‚˜ì¹˜ê²Œ ì„¸ë¶„í™”ë˜ê±°ë‚˜ ê³¼ë„í•˜ê²Œ ë³‘í•©ë˜ì§€ ì•Šì•˜ëŠ”ì§€ ê²€í† 
""",
    "evidence_accuracy": """
[Evidence Accuracy (ê·¼ê±° ì •í™•ì„±)]
ë°œí™” ì›ë¬¸ ì¶”ì¶œ ê¸°ëŠ¥ì´ ì •í™•í•œì§€ í‰ê°€í•©ë‹ˆë‹¤.

ì ìˆ˜ ê¸°ì¤€:
- 5ì  (ì™„ë²½): ì¶”ì¶œëœ Evidence(ë°œí™” êµ¬ê°„)ë§Œ ì½ì–´ë„ í•´ë‹¹ Decisionì„ ë„ì¶œí•  ìˆ˜ ìˆì„ ë§Œí¼ ì •í™•í•œ êµ¬ê°„ ì¸ìš©
- 4ì  (ìš°ìˆ˜): í•µì‹¬ ë°œí™”ëŠ” ì™„ë²½í•˜ê²Œ í¬í•¨ë˜ì–´ ìˆìœ¼ë‚˜, ì „í›„ì˜ ì‚¬ì†Œí•œ ì¡ë‹´ì´ë‚˜ ì—°ê²°ì–´êµ¬ ë“± ë¶ˆí•„ìš”í•œ ë¬¸ì¥ì´ ì•½ê°„(5% ì´í•˜) í¬í•¨ë¨
- 3ì  (ë³´í†µ): ë¶ˆí•„ìš”í•œ ëŒ€í™”ê°€ ë§ì´ ì„ì—¬ ë¬¸ë§¥ íŒŒì•…ì„ ë°©í•´í•˜ê±°ë‚˜(Too broad), í•µì‹¬ ë¬¸ì¥ì˜ ì¼ë¶€ê°€ ì˜ë ¤ ë¬¸ë§¥ ì¶”ë¡ ì´ í•„ìš”í•¨(Too narrow)
- 2ì  (ë¯¸í¡): ë¶ˆí•„ìš”í•œ ëŒ€í™”ê°€ ë§ì´ ì„ì´ë©´ì„œ ë™ì‹œì— í•µì‹¬ ë¬¸ì¥ë„ ì˜ë¦¼ (ê·¼ê±°ë¡œì„œ ë¶ˆì¶©ë¶„)
- 1ì  (ì‹¤íŒ¨): ì œì‹œëœ Evidenceê°€ í•´ë‹¹ Decisionê³¼ ì „í˜€ ë¬´ê´€í•œ ë°œí™”

í‰ê°€ ì‹œ ì£¼ì˜ì‚¬í•­:
- Evidenceë¡œ ì œì‹œëœ ë°œí™” êµ¬ê°„ì´ Decisionì„ ë’·ë°›ì¹¨í•˜ëŠ”ì§€ í™•ì¸
- í•µì‹¬ ë°œí™”ê°€ ëˆ„ë½ë˜ì§€ ì•Šì•˜ëŠ”ì§€, ë¶ˆí•„ìš”í•œ ë°œí™”ê°€ ê³¼ë„í•˜ê²Œ í¬í•¨ë˜ì§€ ì•Šì•˜ëŠ”ì§€ ê²€í† 
""",
    "clarity": """
[Clarity (ëª…í™•ì„±)]
ê²°ì •ì‚¬í•­ì´ ëª…í™•í•˜ê²Œ ì„œìˆ ë˜ì—ˆëŠ”ì§€ í‰ê°€í•©ë‹ˆë‹¤.

ì ìˆ˜ ê¸°ì¤€:
- 5ì  (ì™„ì „ ëª…í™•): Decisionë§Œ ì½ì–´ë„ ë¬´ì—‡ì´ ê²°ì •ë˜ì—ˆëŠ”ì§€ ëª…í™•íˆ ì´í•´ ê°€ëŠ¥
- 4ì  (ëŒ€ë¶€ë¶„ ëª…í™•): ëŒ€ë¶€ë¶„ ëª…í™•í•˜ë‚˜ ì¼ë¶€ ëª¨í˜¸í•¨
- 3ì  (ì ˆë°˜ ëª¨í˜¸): ì ˆë°˜ ì •ë„ê°€ ëª¨í˜¸í•˜ê±°ë‚˜ ì¶”ê°€ ë§¥ë½ì´ í•„ìš”
- 2ì  (ëŒ€ë¶€ë¶„ ëª¨í˜¸): ëŒ€ë¶€ë¶„ ëª¨í˜¸í•˜ì—¬ ì›ë¬¸ ì—†ì´ëŠ” ì´í•´ ì–´ë ¤ì›€
- 1ì  (íŒŒì•… ë¶ˆê°€): ë¬´ì—‡ì´ ê²°ì •ëœ ê±´ì§€ ì „í˜€ íŒŒì•… ë¶ˆê°€

í‰ê°€ ì‹œ ì£¼ì˜ì‚¬í•­:
- Decisionì˜ content, contextë§Œ ì½ê³  ì´í•´ ê°€ëŠ¥í•œì§€ íŒë‹¨
- ëˆ„ê°€(who), ë¬´ì—‡ì„(what), ì–¸ì œê¹Œì§€(when), ì™œ(why) ìš”ì†Œê°€ ì ì ˆíˆ í¬í•¨ë˜ì—ˆëŠ”ì§€ í™•ì¸
""",
}


# =============================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# =============================================================================


def format_utterances(utterances: list[dict[str, Any]]) -> str:
    """ë°œí™” ëª©ë¡ì„ ì½ê¸° ì‰¬ìš´ í…ìŠ¤íŠ¸ë¡œ í¬ë§·"""
    lines = []
    for utt in utterances:
        utt_id = utt.get("id", "")
        speaker = utt.get("speaker_name", "Unknown")
        text = utt.get("text", "")
        lines.append(f"[{utt_id}] {speaker}: {text}")
    return "\n".join(lines)


def extract_evidence_text(
    evidence_spans: list[dict[str, Any]], utterances: list[dict[str, Any]]
) -> str:
    """Evidence spanì„ utterancesì—ì„œ ì—­ì°¸ì¡°í•˜ì—¬ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    if not evidence_spans:
        return "(Evidence ì—†ìŒ)"

    evidence_texts = []
    for span in evidence_spans:
        start_id = span.get("start_utt_id", "")
        end_id = span.get("end_utt_id", "")

        # utterances ìˆœì„œëŒ€ë¡œ start_idë¶€í„° end_idê¹Œì§€ ì¶”ì¶œ
        in_span = False
        span_texts = []
        for utt in utterances:
            if utt["id"] == start_id:
                in_span = True
            if in_span:
                speaker = utt.get("speaker_name", "Unknown")
                text = utt.get("text", "")
                span_texts.append(f"{speaker}: {text}")
            if utt["id"] == end_id:
                break

        if span_texts:
            evidence_texts.append("\n".join(span_texts))

    return "\n---\n".join(evidence_texts)


def format_agenda_for_prompt(
    agenda: dict[str, Any], utterances: list[dict[str, Any]]
) -> str:
    """Agenda ë°ì´í„°ë¥¼ í”„ë¡¬í”„íŠ¸ìš© í…ìŠ¤íŠ¸ë¡œ í¬ë§·"""
    topic = agenda.get("topic", "")
    description = agenda.get("description", "")
    evidence = agenda.get("evidence", [])

    agenda_evidence = extract_evidence_text(evidence, utterances)

    result = "[Agenda]\n"
    result += f"Topic: {topic}\n"
    result += f"Description: {description}\n"
    result += f"Evidence:\n{agenda_evidence}\n"

    decision = agenda.get("decision")
    if decision:
        content = decision.get("content", "")
        context = decision.get("context", "")
        decision_evidence = extract_evidence_text(
            decision.get("evidence", []), utterances
        )

        result += "\n[Decision]\n"
        result += f"Content: {content}\n"
        result += f"Context: {context}\n"
        result += f"Evidence:\n{decision_evidence}\n"
    else:
        result += "\n[Decision]\n(ê²°ì •ì‚¬í•­ ì—†ìŒ)\n"

    return result


# =============================================================================
# í‰ê°€ ë¡œì§
# =============================================================================


def evaluate_single_criterion(
    client: OpenAI,
    criterion: str,
    record: dict[str, Any],
) -> dict[str, Any]:
    """ë‹¨ì¼ í‰ê°€ í•­ëª©ì— ëŒ€í•´ LLM í‰ê°€ ìˆ˜í–‰

    Args:
        client: OpenAI í´ë¼ì´ì–¸íŠ¸
        criterion: í‰ê°€ í•­ëª©ëª… (factuality, comprehensiveness ë“±)
        record: í‰ê°€í•  ë ˆì½”ë“œ (extraction_output + utterances)

    Returns:
        {"score": int, "rationale": str}
    """
    extraction = record["extraction_output"]
    utterances = record["utterances"]

    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    system_prompt = f"""ë‹¹ì‹ ì€ íšŒì˜ë¡ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

{RUBRIC_CRITERIA[criterion]}

[í‰ê°€ ì›ì¹™]
- ì ìˆ˜ëŠ” ë°˜ë“œì‹œ 1~5ì˜ ì •ìˆ˜ë¡œë§Œ ë¶€ì—¬
- ê·¼ê±°ëŠ” í•µì‹¬ë§Œ 1~2ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±
- ì§ˆë¬¸ê³¼ ì‘ë‹µì— ë“œëŸ¬ë‚œ ì •ë³´ë§Œ ì‚¬ìš©í•˜ê³  ì¶”ì •í•˜ì§€ ë§ ê²ƒ

[ì‘ë‹µ í˜•ì‹]
ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{{"score": 4, "rationale": "..."}}
"""

    # ì›ë¬¸ ë°œí™” í¬ë§·
    utterances_text = format_utterances(utterances)

    # Agenda/Decision í¬ë§·
    agendas_text = []
    for i, agenda in enumerate(extraction.get("agendas", [])):
        agendas_text.append(f"\n=== Agenda {i+1} ===\n")
        agendas_text.append(format_agenda_for_prompt(agenda, utterances))

    user_prompt = f"""[ì›ë¬¸ ë°œí™”]
{utterances_text}

[ì¶”ì¶œëœ íšŒì˜ë¡]
Summary: {extraction.get('summary', '')}

{''.join(agendas_text)}

ìœ„ ë‚´ìš©ì„ í‰ê°€í•´ì£¼ì„¸ìš”.
"""

    try:
        response = client.chat.completions.create(
            model=EVALUATION_CONFIG["model"],
            temperature=EVALUATION_CONFIG["temperature"],
            max_tokens=EVALUATION_CONFIG["max_tokens"],
            response_format=EVALUATION_CONFIG["response_format"],
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
        )

        result = json.loads(response.choices[0].message.content)

        # ì ìˆ˜ ê²€ì¦ (1~5 ë²”ìœ„)
        score = result.get("score", 3)
        if not isinstance(score, int) or score < 1 or score > 5:
            print(f"  âš ï¸  ê²½ê³ : {criterion} ì ìˆ˜ ë²”ìœ„ ì˜¤ë¥˜ ({score}), 3ì ìœ¼ë¡œ ëŒ€ì²´")
            score = 3

        return {
            "score": score,
            "rationale": result.get("rationale", ""),
        }

    except Exception as e:
        print(f"  âŒ {criterion} í‰ê°€ ì‹¤íŒ¨: {e}")
        return {
            "score": 0,
            "rationale": f"í‰ê°€ ì‹¤íŒ¨: {str(e)}",
            "error": True,
        }


def evaluate_record(
    client: OpenAI,
    record: dict[str, Any],
    record_id: str,
) -> dict[str, Any]:
    """í•˜ë‚˜ì˜ ë ˆì½”ë“œì— ëŒ€í•´ ëª¨ë“  í‰ê°€ í•­ëª© ìˆ˜í–‰

    Args:
        client: OpenAI í´ë¼ì´ì–¸íŠ¸
        record: í‰ê°€í•  ë ˆì½”ë“œ
        record_id: ë ˆì½”ë“œ ì‹ë³„ì

    Returns:
        {
            "record_id": str,
            "scores": {criterion: int, ...},
            "rationales": {criterion: str, ...},
            "overall_score": float,
            "errors": list[str]
        }
    """
    criteria = [
        "factuality",
        "comprehensiveness",
        "structural_consistency",
        "evidence_accuracy",
        "clarity",
    ]

    scores = {}
    rationales = {}
    errors = []

    print(f"\ní‰ê°€ ì¤‘: {record_id}")

    for criterion in criteria:
        print(f"  - {criterion}...", end=" ", flush=True)
        result = evaluate_single_criterion(client, criterion, record)

        if result.get("error"):
            errors.append(f"{criterion}: {result['rationale']}")
            print("âŒ")
        else:
            scores[criterion] = result["score"]
            rationales[criterion] = result["rationale"]
            print(f"âœ“ ({result['score']}ì )")

    # ì „ì²´ í‰ê·  ì ìˆ˜ ê³„ì‚° (ì—ëŸ¬ ì œì™¸)
    valid_scores = [s for s in scores.values() if s > 0]
    overall_score = sum(valid_scores) / len(valid_scores) if valid_scores else 0.0

    return {
        "record_id": record_id,
        "scores": scores,
        "rationales": rationales,
        "overall_score": round(overall_score, 2),
        "errors": errors if errors else None,
    }


# =============================================================================
# ë©”ì¸ ë¡œì§
# =============================================================================


def load_jsonl(filepath: Path) -> list[dict[str, Any]]:
    """JSONL íŒŒì¼ ë¡œë“œ"""
    records = []
    with open(filepath, "r", encoding="utf-8") as f:
        for line_num, line in enumerate(f, 1):
            line = line.strip()
            if not line:
                continue
            try:
                records.append(json.loads(line))
            except json.JSONDecodeError as e:
                print(f"âš ï¸  ë¼ì¸ {line_num} íŒŒì‹± ì‹¤íŒ¨: {e}")
    return records


def save_results(results: list[dict[str, Any]], output_path: Path):
    """í‰ê°€ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)


def print_summary(results: list[dict[str, Any]]):
    """í‰ê°€ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
    print("\n" + "=" * 70)
    print("í‰ê°€ ê²°ê³¼ ìš”ì•½")
    print("=" * 70)

    if not results:
        print("í‰ê°€ëœ ë ˆì½”ë“œ ì—†ìŒ")
        return

    # í‰ê·  ì ìˆ˜ ê³„ì‚°
    criteria = [
        "factuality",
        "comprehensiveness",
        "structural_consistency",
        "evidence_accuracy",
        "clarity",
    ]

    avg_scores = {}
    for criterion in criteria:
        scores = [
            r["scores"].get(criterion, 0)
            for r in results
            if r["scores"].get(criterion, 0) > 0
        ]
        avg_scores[criterion] = sum(scores) / len(scores) if scores else 0.0

    overall_avg = sum(avg_scores.values()) / len(avg_scores) if avg_scores else 0.0

    print(f"\nì´ í‰ê°€ ë ˆì½”ë“œ: {len(results)}")
    print(f"ì „ì²´ í‰ê·  ì ìˆ˜: {overall_avg:.2f} / 5.0\n")

    print("í•­ëª©ë³„ í‰ê·  ì ìˆ˜:")
    for criterion in criteria:
        print(f"  - {criterion:25s}: {avg_scores[criterion]:.2f}")

    # ì—ëŸ¬ í†µê³„
    error_count = sum(1 for r in results if r.get("errors"))
    if error_count > 0:
        print(f"\nâš ï¸  ì—ëŸ¬ ë°œìƒ ë ˆì½”ë“œ: {error_count}ê°œ")


def main():
    parser = argparse.ArgumentParser(
        description="LLM-as-a-Judge í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ (generate_pr)"
    )
    parser.add_argument(
        "--input",
        "-i",
        type=Path,
        required=True,
        help="ì…ë ¥ JSONL íŒŒì¼ ê²½ë¡œ",
    )
    parser.add_argument(
        "--output",
        "-o",
        type=Path,
        required=True,
        help="ì¶œë ¥ JSON íŒŒì¼ ê²½ë¡œ",
    )
    parser.add_argument(
        "--api-key",
        type=str,
        default=None,
        help="OpenAI API í‚¤ (ê¸°ë³¸: í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEY)",
    )
    parser.add_argument(
        "--limit",
        type=int,
        default=None,
        help="í‰ê°€í•  ë ˆì½”ë“œ ìˆ˜ ì œí•œ (í…ŒìŠ¤íŠ¸ìš©)",
    )

    args = parser.parse_args()

    # API í‚¤ í™•ì¸
    api_key = args.api_key or os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        print("   --api-key ì˜µì…˜ìœ¼ë¡œ ì œê³µí•˜ê±°ë‚˜, OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
        sys.exit(1)

    # ì…ë ¥ íŒŒì¼ í™•ì¸
    if not args.input.exists():
        print(f"âŒ ì…ë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.input}")
        sys.exit(1)

    # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    client = OpenAI(api_key=api_key)

    print(f"ğŸ¤– í‰ê°€ ëª¨ë¸: {EVALUATION_CONFIG['model']}")
    print(f"ğŸ“‚ ì…ë ¥ íŒŒì¼: {args.input}")
    print(f"ğŸ“‚ ì¶œë ¥ íŒŒì¼: {args.output}")

    # JSONL íŒŒì¼ ë¡œë“œ
    print("\nğŸ“¥ JSONL íŒŒì¼ ë¡œë”© ì¤‘...")
    records = load_jsonl(args.input)

    if args.limit:
        records = records[: args.limit]
        print(f"   (ì œí•œ: ì²˜ìŒ {args.limit}ê°œë§Œ í‰ê°€)")

    print(f"   ì´ {len(records)}ê°œ ë ˆì½”ë“œ ë¡œë“œë¨")

    if not records:
        print("âŒ í‰ê°€í•  ë ˆì½”ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit(1)

    # í‰ê°€ ìˆ˜í–‰
    results = []
    for i, record in enumerate(records):
        record_id = record.get("record_id", f"record-{i+1}")
        result = evaluate_record(client, record, record_id)
        results.append(result)

    # ê²°ê³¼ ì €ì¥
    print("\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘...")
    save_results(results, args.output)
    print(f"   âœ“ ì €ì¥ ì™„ë£Œ: {args.output}")

    # ìš”ì•½ ì¶œë ¥
    print_summary(results)

    print("\nâœ… í‰ê°€ ì™„ë£Œ!")


if __name__ == "__main__":
    main()
