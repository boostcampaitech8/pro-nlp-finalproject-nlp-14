import logging

from langchain_core.messages import AIMessage, HumanMessage, SystemMessage

# ğŸ”§ FIX: tools íŒ¨í‚¤ì§€ ì „ì²´ë¥¼ importí•˜ì—¬ query/mutation ë„êµ¬ë“¤ì´ registryì— ë“±ë¡ë˜ë„ë¡ í•¨
import app.infrastructure.graph.orchestration.tools  # noqa: F401
from app.infrastructure.graph.integration.llm import get_planner_llm_for_tools
from app.infrastructure.graph.orchestration.state import OrchestrationState
from app.infrastructure.graph.orchestration.tools.registry import (
    InteractionMode,
    get_langchain_tools_for_mode,
    get_tool_category,
    normalize_interaction_mode,
)
from app.prompt.v1.orchestration.planning import (
    TOOL_UNAVAILABLE_MESSAGES,  # noqa: F401  # Re-export for other modules
    build_spotlight_system_prompt,
    build_voice_system_prompt,
)

logger = logging.getLogger(__name__)


async def create_plan(state: OrchestrationState) -> OrchestrationState:
    """ê³„íš ìˆ˜ë¦½ ë…¸ë“œ - bind_tools ë°©ì‹

    Contract:
        reads: messages, retry_count, planning_context, tool_results, interaction_mode, user_context
        writes: plan, need_tools, can_answer, selected_tool, tool_category, tool_args
        side-effects: LLM API í˜¸ì¶œ
        failures: PLANNING_FAILED -> ê¸°ë³¸ ê³„íš ë°˜í™˜
    """
    logger.info("Planning ë‹¨ê³„ ì§„ì…")

    messages = state.get("messages", [])
    query = messages[-1].content if messages else ""

    # skip_planning ì²˜ë¦¬ (HITL ì‘ë‹µ ì‹œ)
    if state.get("skip_planning") and state.get("plan"):
        logger.info("Planning ë‹¨ê³„ ìŠ¤í‚µ: ê¸°ì¡´ plan ì‚¬ìš©")
        logger.info(f"hitl_status ë³´ì¡´: {state.get('hitl_status')}")
        return OrchestrationState(
            plan=state.get("plan", ""),
            need_tools=state.get("need_tools", False),
            can_answer=state.get("can_answer", True),
            missing_requirements=state.get("missing_requirements", []),
            selected_tool=state.get("selected_tool"),
            tool_category=state.get("tool_category"),
            tool_args=state.get("tool_args", {}),
            # HITL ìƒíƒœ ë³´ì¡´ (confirmed/cancelled ìƒíƒœê°€ tools ë…¸ë“œì— ì „ë‹¬ë˜ì–´ì•¼ í•¨)
            hitl_status=state.get("hitl_status"),
        )

    # ëª¨ë“œ ë° ë„êµ¬ ì„¤ì •
    mode = normalize_interaction_mode(state.get("interaction_mode", "voice"))

    langchain_tools = get_langchain_tools_for_mode(mode)
    logger.info(f"Interaction mode: {mode.value}, tools count: {len(langchain_tools)}")

    # bind_tools ì ìš© (thinking íŒŒë¼ë¯¸í„° ì—†ëŠ” LLM ì‚¬ìš©)
    llm = get_planner_llm_for_tools()
    llm_with_tools = llm.bind_tools(langchain_tools)

    # ëª¨ë“œë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (prompts ëª¨ë“ˆì—ì„œ ë¹Œë“œ)
    if mode == InteractionMode.SPOTLIGHT:
        user_context = state.get("user_context", {})
        system_prompt = build_spotlight_system_prompt(user_context)
    else:
        meeting_id = state.get("meeting_id", "unknown")
        system_prompt = build_voice_system_prompt(meeting_id)

    # ì´ì „ ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ì— í¬í•¨
    planning_context = state.get("planning_context", "")
    tool_results = state.get("tool_results", "")
    if tool_results:
        if planning_context:
            planning_context = f"[ì´ì „ ë„êµ¬ ì‹¤í–‰ ê²°ê³¼]\n{tool_results}\n\n{planning_context}"
        else:
            planning_context = f"[ì´ì „ ë„êµ¬ ì‹¤í–‰ ê²°ê³¼]\n{tool_results}"
        logger.info(f"tool_resultsë¥¼ planning_contextì— í¬í•¨ (ê¸¸ì´: {len(tool_results)})")

    # ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
    if planning_context:
        system_prompt += f"\n\n[ì»¨í…ìŠ¤íŠ¸]\n{planning_context}"

    # ë©”ì‹œì§€ êµ¬ì„±
    chat_messages = [SystemMessage(content=system_prompt)]

    # ì´ì „ ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬í•¨ (ìµœê·¼ 10ê°œ, í˜„ì¬ ë©”ì‹œì§€ ì œì™¸)
    if len(messages) > 1:
        for msg in messages[-11:-1]:
            if msg.type == "human":
                chat_messages.append(HumanMessage(content=msg.content))
            else:
                chat_messages.append(AIMessage(content=msg.content))

    # í˜„ì¬ ë©”ì‹œì§€
    chat_messages.append(HumanMessage(content=query))

    try:
        # ì§„ë‹¨ ë¡œê¹…: LLMì— ì „ì†¡ë˜ëŠ” ë„êµ¬ ì •ë³´
        logger.info(f"Tools being sent to LLM: {[t.name for t in langchain_tools]}")
        logger.debug(f"Tool schemas: {[t.args_schema.schema() if t.args_schema else None for t in langchain_tools]}")

        # LLM í˜¸ì¶œ (bind_tools ì ìš©ëœ ëª¨ë¸)
        response: AIMessage = await llm_with_tools.ainvoke(chat_messages)

        # ì§„ë‹¨ ë¡œê¹…: LLM ì‘ë‹µ ë¶„ì„
        logger.info(f"LLM response type: {type(response).__name__}")
        logger.info(f"Has tool_calls: {bool(response.tool_calls)}")
        if response.tool_calls:
            logger.info(f"tool_calls content: {response.tool_calls}")
        else:
            logger.info(f"Response content (first 200 chars): {str(response.content)[:200]}")

        # tool_calls íŒŒì‹±
        if response.tool_calls:
            first_call = response.tool_calls[0]
            tool_name = first_call["name"]
            tool_args = first_call.get("args", {})

            tool_category = get_tool_category(tool_name) or "query"

            logger.info(f"ë„êµ¬ ì„ íƒë¨: {tool_name}")
            logger.info(f"ë„êµ¬ ì¸ì: {tool_args}")
            logger.info(f"ë„êµ¬ ì¹´í…Œê³ ë¦¬: {tool_category}")

            return OrchestrationState(
                messages=[response],
                selected_tool=tool_name,
                tool_args=tool_args,
                tool_category=tool_category,
                need_tools=False,
                can_answer=True,
                plan=f"ë„êµ¬ ì‹¤í–‰: {tool_name}",
                missing_requirements=[],
            )
        else:
            # ë„êµ¬ ì—†ì´ ì§ì ‘ ì‘ë‹µ
            logger.info("ë„êµ¬ ì—†ì´ ì§ì ‘ ì‘ë‹µ")
            logger.info(f"ì‘ë‹µ ë‚´ìš©: {response.content[:100]}..." if response.content else "ì‘ë‹µ ì—†ìŒ")

            return OrchestrationState(
                messages=[response],
                response=response.content,
                can_answer=True,
                need_tools=False,
                plan="ì§ì ‘ ì‘ë‹µ",
                selected_tool=None,
                tool_category=None,
                tool_args={},
                missing_requirements=[],
            )

    except Exception as e:
        logger.error(f"Planning ë‹¨ê³„ì—ì„œ ì—ëŸ¬ ë°œìƒ: {e}")
        return OrchestrationState(
            plan="ì§ˆë¬¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ",
            need_tools=False,
            can_answer=True,
            missing_requirements=["query_analysis_error"],
            selected_tool=None,
            tool_category=None,
            tool_args={},
        )
