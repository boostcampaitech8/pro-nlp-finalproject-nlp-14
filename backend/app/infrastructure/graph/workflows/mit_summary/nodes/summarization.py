"""ìš”ì•½ ìƒì„± ë…¸ë“œ"""

import logging
from datetime import datetime

from langchain_community.chat_models import ChatClovaX
from langchain_core.output_parsers import PydanticOutputParser
from langchain_core.prompts import ChatPromptTemplate

from app.infrastructure.graph.config import NCP_CLOVASTUDIO_API_KEY
from app.infrastructure.graph.schema.models import SummaryOutput, Utterance
from app.infrastructure.graph.workflows.mit_summary.state import MitSummaryState

logger = logging.getLogger(__name__)

# Summary ì „ìš© LLM (ë‚®ì€ temperatureë¡œ ì •í™•ì„± í–¥ìƒ)
summary_llm = ChatClovaX(
    temperature=0.1,
    max_tokens=1024,
    model="HCX-003",
    api_key=NCP_CLOVASTUDIO_API_KEY,
)


async def generate_summary(state: MitSummaryState) -> MitSummaryState:
    """LLMìœ¼ë¡œ íšŒì˜ ìš”ì•½ ìƒì„± (í•˜ì´í¼í´ë¡œë°”X)

    Contract:
        reads: mit_summary_utterances_raw, mit_summary_contradictions, mit_summary_metadata
        writes: mit_summary_result, mit_summary_text
        side-effects: LLM API í˜¸ì¶œ (HyperCLOVA X)
        failures: SUMMARY_GENERATION_FAILED -> errors ê¸°ë¡

    êµ¬í˜„ ì „ëµ:
    1. messagesì—ì„œ ì¶”ì¶œí•œ ë°œí™”ë¥¼ ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬
    2. ë°œí™” í…ìŠ¤íŠ¸ë¥¼ LLM ì…ë ¥ í˜•ì‹ìœ¼ë¡œ í¬ë§¤íŒ…
    3. í•˜ì´í¼í´ë¡œë°”X í˜¸ì¶œ (temperature ë‚®ê²Œ)
    4. êµ¬ì¡°í™”ëœ ì‘ë‹µ íŒŒì‹± -> SummaryOutput
    5. ìì—°ì–´ ì‘ë‹µ ìƒì„± (contradictions í¬í•¨)
    """
    logger.info("ìš”ì•½ ìƒì„± ì‹œì‘")

    utterances = state.get("mit_summary_utterances_raw", [])
    contradictions = state.get("mit_summary_contradictions", [])
    metadata = state.get("mit_summary_metadata", {})

    if not utterances:
        logger.warning("ìš”ì•½í•  ë°œí™” ì—†ìŒ")
        return MitSummaryState(
            mit_summary_text="ìš”ì•½í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.",
            mit_summary_result=SummaryOutput(
                overall="ìš”ì•½í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.", key_points=[]
            ),
        )

    try:
        # ë°œí™” í…ìŠ¤íŠ¸ í¬ë§¤íŒ…
        formatted_text = _format_utterances_for_llm(utterances)
        logger.debug(f"í¬ë§¤íŒ…ëœ ë°œí™” ê¸¸ì´: {len(formatted_text)} ë¬¸ì")

        # LLM í˜¸ì¶œë¡œ ìš”ì•½ ìƒì„±
        parser = PydanticOutputParser(pydantic_object=SummaryOutput)

        prompt = ChatPromptTemplate.from_template(
            "ë‹¹ì‹ ì€ íšŒì˜ ë‚´ìš©ì„ ì •í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ëŠ” AI ë¹„ì„œì…ë‹ˆë‹¤.\n\n"
            "ë‹¤ìŒì€ íšŒì˜ ë°œí™” ê¸°ë¡ì…ë‹ˆë‹¤:\n\n"
            "{utterances}\n\n"
            "ìœ„ íšŒì˜ ë‚´ìš©ì„ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:\n"
            "1. overall: ì „ì²´ íšŒì˜ ë‚´ìš©ì„ 3-5ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½\n"
            "2. key_points: ê°€ì¥ ì¤‘ìš”í•œ í¬ì¸íŠ¸ 3-5ê°œ (ë¦¬ìŠ¤íŠ¸)\n"
            "3. topics: í† í”½ë³„ ìš”ì•½ (ì„ íƒì )\n"
            "4. decisions_mentioned: íšŒì˜ ì¤‘ ì–¸ê¸‰ëœ ê²°ì •ì‚¬í•­ì´ë‚˜ í•©ì˜ ë‚´ìš©\n\n"
            "ì¤‘ìš”: ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”!\n\n"
            "{format_instructions}"
        )

        chain = prompt | summary_llm | parser

        logger.info("LLM í˜¸ì¶œ ì‹œì‘ (HyperCLOVA X)")
        summary_result = chain.invoke(
            {
                "utterances": formatted_text,
                "format_instructions": parser.get_format_instructions(),
            }
        )

        # contradictions ì¶”ê°€
        if contradictions:
            summary_result.contradictions = contradictions

        # metadata ì¶”ê°€
        summary_result.summary_metadata = {
            **metadata,
            "generated_at": datetime.utcnow().isoformat(),
            "llm_model": "HCX-003",
            "utterance_count": len(utterances),
        }

        logger.info("ìš”ì•½ ìƒì„± ì„±ê³µ")

        # ìì—°ì–´ ì‘ë‹µ ìƒì„±
        summary_text = _build_natural_language_response(summary_result)

        # ìì²´ í‰ê°€
        evaluation_passed, evaluation_reason = _self_evaluate_summary(
            summary_result, utterances
        )

        logger.info(f"ìì²´ í‰ê°€: {evaluation_passed} - {evaluation_reason}")

        return MitSummaryState(
            mit_summary_result=summary_result,
            mit_summary_text=summary_text,
            mit_summary_self_evaluation_passed=evaluation_passed,
            mit_summary_self_evaluation_reason=evaluation_reason,
            tool_results=summary_text,  # Orchestrationì—ì„œ ì‚¬ìš©
        )

    except Exception as e:
        logger.exception("ìš”ì•½ ìƒì„± ì‹¤íŒ¨")
        return MitSummaryState(
            mit_summary_errors={
                "generate_summary": f"SUMMARY_GENERATION_FAILED: {str(e)}"
            }
        )


def _format_utterances_for_llm(utterances: list[Utterance]) -> str:
    """ë°œí™” ëª©ë¡ì„ LLM ì…ë ¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜

    í˜•ì‹:
    [00:00:15] í™ê¸¸ë™: ì•ˆë…•í•˜ì„¸ìš”. íšŒì˜ë¥¼ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤.
    [00:00:23] ê¹€ì² ìˆ˜: ë„¤, ì˜¤ëŠ˜ ì•ˆê±´ì€ ì˜ˆì‚° ê´€ë ¨ì…ë‹ˆë‹¤.
    ...
    """
    lines = []
    for utt in sorted(utterances, key=lambda u: u.start_time):
        timestamp_str = _format_timestamp(utt.start_time)
        lines.append(f"[{timestamp_str}] {utt.speaker_name}: {utt.text}")

    return "\n".join(lines)


def _format_timestamp(seconds: float) -> str:
    """ì´ˆë¥¼ [HH:MM:SS] í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    return f"{hours:02d}:{minutes:02d}:{secs:02d}"


def _build_natural_language_response(summary: SummaryOutput) -> str:
    """SummaryOutputì„ ìì—°ì–´ ì‘ë‹µìœ¼ë¡œ ë³€í™˜

    ì„¤ê³„ ê²°ì •:
    - ì „ì²´ ìš”ì•½ + í•µì‹¬ í¬ì¸íŠ¸ë¥¼ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ì¡°í•©
    - ëª¨ìˆœì´ ê°ì§€ë˜ë©´ ê²½ê³  ì¶”ê°€
    - ë§ˆí¬ë‹¤ìš´ í˜•ì‹ ì§€ì› (UIì—ì„œ ë Œë”ë§)
    """
    parts = []

    # ì „ì²´ ìš”ì•½
    parts.append(f"## ğŸ“‹ íšŒì˜ ìš”ì•½\n\n{summary.overall}")

    # í•µì‹¬ í¬ì¸íŠ¸
    if summary.key_points:
        parts.append("\n## ğŸ”‘ í•µì‹¬ í¬ì¸íŠ¸\n")
        for i, point in enumerate(summary.key_points, 1):
            parts.append(f"{i}. {point}")

    # í† í”½ë³„ ìš”ì•½
    if summary.topics:
        parts.append("\n## ğŸ“Œ í† í”½ë³„ ìš”ì•½\n")
        for topic in summary.topics:
            parts.append(f"**{topic['topic']}**\n{topic['summary']}\n")

    # ì–¸ê¸‰ëœ ê²°ì •ì‚¬í•­
    if summary.decisions_mentioned:
        parts.append("\n## âœ… ì–¸ê¸‰ëœ ê²°ì •ì‚¬í•­\n")
        for decision in summary.decisions_mentioned:
            parts.append(f"- {decision}")

    # ëª¨ìˆœ ê²½ê³ 
    if summary.contradictions:
        parts.append("\n## âš ï¸ ëª¨ìˆœ ê°ì§€\n")
        parts.append(
            f"ê¸°ì¡´ GTì™€ ëª¨ìˆœë˜ëŠ” ë‚´ìš©ì´ {len(summary.contradictions)}ê±´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
        )
        for i, contradiction in enumerate(summary.contradictions, 1):
            severity_emoji = {
                "low": "ğŸŸ¡",
                "medium": "ğŸŸ ",
                "high": "ğŸ”´",
            }.get(contradiction.severity, "âšª")
            parts.append(
                f"{i}. {severity_emoji} **{contradiction.gt_decision.agenda_topic}**\n"
                f"   - ë°œí™”: \"{contradiction.utterance_text[:100]}...\"\n"
                f"   - ê¸°ì¡´ ê²°ì •: \"{contradiction.gt_decision.content[:100]}...\"\n"
                f"   - ì‚¬ìœ : {contradiction.reason}\n"
            )

    return "\n".join(parts)


def _self_evaluate_summary(
    summary: SummaryOutput, utterances: list[Utterance]
) -> tuple[bool, str]:
    """ìš”ì•½ ê²°ê³¼ë¥¼ ìì²´ í‰ê°€

    í‰ê°€ ê¸°ì¤€:
    1. overall_summary ì¡´ì¬ ë° ìµœì†Œ ê¸¸ì´
    2. key_points ê°œìˆ˜
    3. ì…ë ¥ ëŒ€ë¹„ ìš”ì•½ ë¹„ìœ¨

    Returns:
        (passed, reason) íŠœí”Œ
    """
    # ê¸°ë³¸ í•„ë“œ ì¡´ì¬ í™•ì¸
    if not summary.overall:
        return False, "overall_summaryê°€ ë¹„ì–´ìˆìŒ"

    # ìµœì†Œ ê¸¸ì´ í™•ì¸ (50ì)
    if len(summary.overall) < 50:
        return False, f"overall_summary ë„ˆë¬´ ì§§ìŒ ({len(summary.overall)}ì < 50ì)"

    # key_points ê°œìˆ˜ í™•ì¸
    if not summary.key_points or len(summary.key_points) < 2:
        return (
            False,
            f"key_points ë¶€ì¡± ({len(summary.key_points) if summary.key_points else 0}ê°œ < 2ê°œ)",
        )

    # key_points ê° í•­ëª© ê¸¸ì´ í™•ì¸
    for i, point in enumerate(summary.key_points):
        if len(point) < 10:
            return False, f"key_points[{i}] ë„ˆë¬´ ì§§ìŒ ({len(point)}ì)"

    # ì…ë ¥ ëŒ€ë¹„ ìš”ì•½ ë¹„ìœ¨ í™•ì¸ (ë„ˆë¬´ ê¸´ ê²½ìš° ìš”ì•½ì´ ì•„ë‹˜)
    total_input_length = sum(len(u.text) for u in utterances)
    summary_length = len(summary.overall) + sum(len(p) for p in summary.key_points)

    if total_input_length > 0:
        compression_ratio = summary_length / total_input_length
        if compression_ratio > 0.8:  # ìš”ì•½ì´ ì›ë¬¸ì˜ 80% ì´ìƒì´ë©´ ì‹¤íŒ¨
            return False, f"ì••ì¶•ë¥  ë¶€ì¡± (ìš”ì•½/ì›ë¬¸ = {compression_ratio:.2f} > 0.8)"

    # ëª¨ë“  ì¡°ê±´ í†µê³¼
    return True, "ëª¨ë“  í’ˆì§ˆ ê¸°ì¤€ ì¶©ì¡±"
